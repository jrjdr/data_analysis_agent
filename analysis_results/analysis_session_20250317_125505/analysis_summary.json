{
  "timestamp": "20250317_125505",
  "structure_analysis": {
    "file_path": "temp_csv/excel_data_20250317125505.csv",
    "row_count": 14400,
    "column_count": 36,
    "columns": {
      "timestamp": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 1440,
        "most_common": {
          "value": "2025-02-28 23:43:00",
          "count": 10
        }
      },
      "server_id": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 10,
        "most_common": {
          "value": "SRV001",
          "count": 1440
        }
      },
      "server_name": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 10,
        "most_common": {
          "value": "主应用服务器",
          "count": 1440
        }
      },
      "resource_type": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 2,
        "most_common": {
          "value": "server",
          "count": 7200
        }
      },
      "cpu_usage_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7197,
        "min": 5.583852264688791,
        "max": 100.0,
        "mean": 37.580310160571194,
        "median": 31.618053991508955
      },
      "memory_usage_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 27.40743739744767,
        "max": 100.0,
        "mean": 53.56874487701693,
        "median": 51.703927240468204
      },
      "disk_usage_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 2083,
        "min": 50.0,
        "max": 89.15643708778276,
        "mean": 52.842364900407624,
        "median": 50.0
      },
      "disk_io_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.4762013327438215,
        "max": 92.99558435884306,
        "mean": 29.27332977011458,
        "median": 23.18286926147777
      },
      "disk_read_mbps": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.2630234131950719,
        "max": 180.2153282172936,
        "mean": 37.037291892330146,
        "median": 28.136800228562365
      },
      "disk_write_mbps": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.182086591097093,
        "max": 137.1202666644026,
        "mean": 26.24042230099243,
        "median": 19.716467316167673
      },
      "network_traffic_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7190,
        "min": 5.218084351700895,
        "max": 100.0,
        "mean": 38.25191151335494,
        "median": 32.304874905255105
      },
      "network_in_mbps": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 3.664073875573308,
        "max": 298.5663943168601,
        "mean": 66.60107367863556,
        "median": 52.31586370927587
      },
      "network_out_mbps": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 2.018538415519138,
        "max": 194.9236017252965,
        "mean": 44.220199227491264,
        "median": 34.76118873398282
      },
      "load_avg_1min": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7197,
        "min": 0.2233540905875517,
        "max": 4.0,
        "mean": 1.503212406422848,
        "median": 1.264722159660358
      },
      "load_avg_5min": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.1969890937230561,
        "max": 4.637323717287012,
        "mean": 1.50334320642707,
        "median": 1.255915664903009
      },
      "load_avg_15min": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.1742767263645276,
        "max": 4.865296032228876,
        "mean": 1.501586154410839,
        "median": 1.2650191688980905
      },
      "process_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 192,
        "min": 104.0,
        "max": 305.0,
        "mean": 174.54805555555555,
        "median": 163.0
      },
      "thread_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 1460,
        "min": 321.0,
        "max": 2330.0,
        "mean": 963.66625,
        "median": 914.0
      },
      "open_file_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 3878,
        "min": 761.0,
        "max": 10032.0,
        "mean": 3376.4056944444446,
        "median": 3083.0
      },
      "temperature_celsius": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 35.00103782917293,
        "max": 64.99493956200003,
        "mean": 50.18363588060569,
        "median": 50.26199601251966
      },
      "event_type": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 5,
        "most_common": {
          "value": "normal",
          "count": 14103
        }
      },
      "query_rate_per_sec": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 51.60447173041226,
        "max": 1242.155211670172,
        "mean": 349.16422296415624,
        "median": 242.7240593882832
      },
      "active_connections": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 5.088021600619555,
        "max": 196.4773247084502,
        "mean": 40.829048216631215,
        "median": 31.254083457647873
      },
      "cache_hit_rate_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 27.49392502510446,
        "max": 99.80770989390808,
        "mean": 84.69415779469541,
        "median": 85.52261438877517
      },
      "avg_query_time_ms": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 8.218560972964452,
        "max": 246.5327044433118,
        "mean": 18.00781146462357,
        "median": 16.86848109365319
      },
      "transactions_per_sec": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 3.640326505424797,
        "max": 218.7554534911781,
        "mean": 38.264386582507335,
        "median": 25.92668158026779
      },
      "read_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 66.66771801657447,
        "max": 88.88710362366339,
        "mean": 81.80204128259189,
        "median": 83.4281277352871
      },
      "write_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 11.11289637633661,
        "max": 33.33228198342553,
        "mean": 18.197958717408124,
        "median": 16.571872264712894
      },
      "lock_wait_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 30,
        "min": 0.0,
        "max": 37.0,
        "mean": 3.6131944444444444,
        "median": 2.0
      },
      "deadlock_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 4,
        "min": 0.0,
        "max": 3.0,
        "mean": 0.022916666666666665,
        "median": 0.0
      },
      "buffer_pool_usage_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 50.00219015090894,
        "max": 94.99539755412248,
        "mean": 72.37492448959392,
        "median": 72.35257430227293
      },
      "table_scans_per_sec": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.0053320997153272,
        "max": 49.99914923662595,
        "mean": 25.043416152890018,
        "median": 25.287476707940492
      },
      "index_usage_percent": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 60.00018636575737,
        "max": 98.99423242150068,
        "mean": 79.49692425207539,
        "median": 79.56311351381834
      },
      "temp_tables_created_per_sec": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 7200,
        "min": 0.0022427939408053,
        "max": 19.99778780401121,
        "mean": 10.12595589164474,
        "median": 10.169087769131885
      },
      "slow_queries_count": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 49,
        "min": 0.0,
        "max": 57.0,
        "mean": 8.281944444444445,
        "median": 5.0
      },
      "aborted_connections": {
        "type": "float64",
        "missing_values": 7200,
        "unique_values": 6,
        "min": 0.0,
        "max": 5.0,
        "mean": 0.2263888888888889,
        "median": 0.0
      }
    }
  },
  "column_names": [
    "timestamp",
    "server_id",
    "server_name",
    "resource_type",
    "cpu_usage_percent",
    "memory_usage_percent",
    "disk_usage_percent",
    "disk_io_percent",
    "disk_read_mbps",
    "disk_write_mbps",
    "network_traffic_percent",
    "network_in_mbps",
    "network_out_mbps",
    "load_avg_1min",
    "load_avg_5min",
    "load_avg_15min",
    "process_count",
    "thread_count",
    "open_file_count",
    "temperature_celsius",
    "event_type",
    "query_rate_per_sec",
    "active_connections",
    "cache_hit_rate_percent",
    "avg_query_time_ms",
    "transactions_per_sec",
    "read_percent",
    "write_percent",
    "lock_wait_count",
    "deadlock_count",
    "buffer_pool_usage_percent",
    "table_scans_per_sec",
    "index_usage_percent",
    "temp_tables_created_per_sec",
    "slow_queries_count",
    "aborted_connections"
  ],
  "results": {
    "总体数据统计分析单元": {
      "status": "success",
      "error": null,
      "code": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport json\nimport os\nfrom datetime import datetime\n\n# 设置中文字体支持\nplt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\nplt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n\ndef analyze_csv_data(file_path):\n    try:\n        # 1. 读取CSV文件\n        print(f\"正在读取文件: {file_path}\")\n        df = pd.read_csv(file_path)\n        \n        # 确保时间戳列是日期时间类型\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n        \n        # 2. 基本描述性统计分析\n        print(\"正在进行基本统计分析...\")\n        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n        categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n        \n        # 创建输出目录\n        output_dir = \"pngs\"\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        \n        # 3. 分析数值列和分类列的分布\n        stats_result = {\n            \"file_info\": {\n                \"file_path\": file_path,\n                \"row_count\": len(df),\n                \"column_count\": len(df.columns)\n            },\n            \"numeric_stats\": {},\n            \"categorical_stats\": {},\n            \"charts\": []\n        }\n        \n        # 数值列统计\n        for col in numeric_columns:\n            if df[col].notna().any():  # 确保列不是全部为NaN\n                stats_result[\"numeric_stats\"][col] = {\n                    \"mean\": float(df[col].mean()),\n                    \"median\": float(df[col].median()),\n                    \"std\": float(df[col].std()),\n                    \"min\": float(df[col].min()),\n                    \"max\": float(df[col].max()),\n                    \"missing_values\": int(df[col].isna().sum())\n                }\n        \n        # 分类列统计\n        for col in categorical_columns:\n            value_counts = df[col].value_counts()\n            stats_result[\"categorical_stats\"][col] = {\n                \"unique_values\": int(df[col].nunique()),\n                \"most_common\": {\n                    \"value\": value_counts.index[0],\n                    \"count\": int(value_counts.iloc[0])\n                },\n                \"missing_values\": int(df[col].isna().sum())\n            }\n        \n        # 4. 生成统计图表\n        print(\"正在生成统计图表...\")\n        \n        # 图表1: 服务器资源使用情况热力图\n        plt.figure(figsize=(14, 10))\n        resource_cols = ['cpu_usage_percent', 'memory_usage_percent', 'disk_usage_percent', \n                         'network_traffic_percent', 'temperature_celsius']\n        \n        # 按服务器和时间聚合数据\n        pivot_df = df.pivot_table(\n            index='server_name', \n            values=resource_cols,\n            aggfunc='mean'\n        ).sort_values('cpu_usage_percent', ascending=False)\n        \n        # 绘制热力图\n        sns.heatmap(pivot_df, annot=True, fmt=\".1f\", cmap=\"YlOrRd\", linewidths=.5)\n        plt.title('Average Resource Usage by Server')\n        plt.tight_layout()\n        \n        chart1_path = os.path.join(output_dir, f\"chart_stats_resource_heatmap_{datetime.now().strftime('%Y%m%d%H%M%S')}.png\")\n        plt.savefig(chart1_path)\n        plt.close()\n        \n        stats_result[\"charts\"].append({\n            \"title\": \"Average Resource Usage by Server\",\n            \"description\": \"Heatmap showing average resource utilization across different servers. Higher values (darker colors) indicate higher resource usage.\",\n            \"path\": chart1_path\n        })\n        \n        # 图表2: 数据库性能指标时间序列\n        plt.figure(figsize=(14, 8))\n        \n        # 选择数据库类型的记录\n        db_df = df[df['resource_type'] == 'database'].copy()\n        if not db_df.empty:\n            # 按时间聚合数据\n            db_df.set_index('timestamp', inplace=True)\n            db_hourly = db_df.resample('H').mean()\n            \n            # 绘制多指标时间序列图\n            ax = db_hourly['query_rate_per_sec'].plot(label='Query Rate (per sec)', color='blue')\n            ax2 = ax.twinx()\n            db_hourly['avg_query_time_ms'].plot(ax=ax2, label='Avg Query Time (ms)', color='red')\n            \n            ax.set_xlabel('Time')\n            ax.set_ylabel('Queries per Second')\n            ax2.set_ylabel('Average Query Time (ms)')\n            \n            # 合并图例\n            lines1, labels1 = ax.get_legend_handles_labels()\n            lines2, labels2 = ax2.get_legend_handles_labels()\n            ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n            \n            plt.title('Database Performance Metrics Over Time')\n            plt.grid(True, alpha=0.3)\n            plt.tight_layout()\n            \n            chart2_path = os.path.join(output_dir, f\"chart_stats_db_performance_{datetime.now().strftime('%Y%m%d%H%M%S')}.png\")\n            plt.savefig(chart2_path)\n            plt.close()\n            \n            stats_result[\"charts\"].append({\n                \"title\": \"Database Performance Metrics Over Time\",\n                \"description\": \"Time series showing query rate and average query time. Reveals performance patterns and potential bottlenecks over time.\",\n                \"path\": chart2_path\n            })\n        else:\n            # 如果没有数据库记录，创建一个替代图表\n            # 图表2(替代): 系统负载随时间变化\n            plt.figure(figsize=(14, 8))\n            \n            # 按时间聚合数据\n            df.set_index('timestamp', inplace=True)\n            hourly_data = df.resample('H').mean()\n            \n            ax = hourly_data['load_avg_1min'].plot(label='1 min', color='blue')\n            hourly_data['load_avg_5min'].plot(ax=ax, label='5 min', color='green')\n            hourly_data['load_avg_15min'].plot(ax=ax, label='15 min', color='red')\n            \n            ax.set_xlabel('Time')\n            ax.set_ylabel('System Load Average')\n            ax.legend()\n            \n            plt.title('System Load Average Over Time')\n            plt.grid(True, alpha=0.3)\n            plt.tight_layout()\n            \n            chart2_path = os.path.join(output_dir, f\"chart_stats_system_load_{datetime.now().strftime('%Y%m%d%H%M%S')}.png\")\n            plt.savefig(chart2_path)\n            plt.close()\n            \n            stats_result[\"charts\"].append({\n                \"title\": \"System Load Average Over Time\",\n                \"description\": \"Time series showing system load averages at different intervals (1, 5, and 15 minutes). Helps identify periods of high system stress.\",\n                \"path\": chart2_path\n            })\n        \n        # 图表3: 事件类型分布饼图\n        plt.figure(figsize=(10, 8))\n        event_counts = df['event_type'].value_counts()\n        plt.pie(event_counts, labels=event_counts.index, autopct='%1.1f%%', \n                startangle=90, shadow=True, explode=[0.05]*len(event_counts))\n        plt.axis('equal')\n        plt.title('Distribution of Event Types')\n        \n        chart3_path = os.path.join(output_dir, f\"chart_stats_event_types_{datetime.now().strftime('%Y%m%d%H%M%S')}.png\")\n        plt.savefig(chart3_path)\n        plt.close()\n        \n        stats_result[\"charts\"].append({\n            \"title\": \"Distribution of Event Types\",\n            \"description\": \"Pie chart showing the distribution of different event types. Normal events dominate, with various alert types making up a small percentage.\",\n            \"path\": chart3_path\n        })\n        \n        # 5. 将分析结果保存为JSON格式\n        json_path = os.path.join(output_dir, f\"stats_analysis_{datetime.now().strftime('%Y%m%d%H%M%S')}.json\")\n        with open(json_path, 'w', encoding='utf-8') as f:\n            json.dump(stats_result, f, ensure_ascii=False, indent=2)\n        \n        print(f\"分析完成! 结果已保存到 {json_path}\")\n        print(f\"生成的图表已保存到 {output_dir} 目录\")\n        \n        return stats_result\n        \n    except Exception as e:\n        print(f\"错误: {str(e)}\")\n        return {\"error\": str(e)}\n\nif __name__ == \"__main__\":\n    file_path = \"temp_csv/excel_data_20250317125505.csv\"\n    analyze_csv_data(file_path)",
      "results": "正在读取文件: temp_csv/excel_data_20250317125505.csv\n正在进行基本统计分析...\n正在生成统计图表...\n错误: agg function failed [how->mean,dtype->object]\n",
      "json_results": null
    }
  }
}
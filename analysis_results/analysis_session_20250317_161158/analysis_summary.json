{
  "timestamp": "20250317_161821",
  "structure_analysis": {
    "file_path": "temp_csv/excel_data_20250317161158.csv",
    "row_count": 64800,
    "column_count": 10,
    "columns": {
      "Timestamp": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 720,
        "most_common": {
          "value": "2025-03-02 07:00:00",
          "count": 90
        }
      },
      "Region": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 5,
        "most_common": {
          "value": "North",
          "count": 12960
        }
      },
      "Service_Type": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 6,
        "most_common": {
          "value": "Voice",
          "count": 10800
        }
      },
      "Network_Type": {
        "type": "object",
        "missing_values": 0,
        "unique_values": 3,
        "most_common": {
          "value": "4G",
          "count": 21600
        }
      },
      "Traffic_Volume_GB": {
        "type": "float64",
        "missing_values": 0,
        "unique_values": 50696,
        "min": 0.0,
        "max": 19930.14,
        "mean": 1343.2243436728395,
        "median": 456.97
      },
      "Active_Users": {
        "type": "int64",
        "missing_values": 0,
        "unique_values": 1608,
        "min": 0,
        "max": 2445,
        "mean": 189.78743827160494,
        "median": 96.0
      },
      "Bandwidth_Utilization_Percent": {
        "type": "float64",
        "missing_values": 0,
        "unique_values": 7019,
        "min": 0.0,
        "max": 95.0,
        "mean": 13.164103549382714,
        "median": 4.55
      },
      "Average_Speed_Mbps": {
        "type": "float64",
        "missing_values": 0,
        "unique_values": 53557,
        "min": 10.02,
        "max": 1999.88,
        "mean": 757.5135956790124,
        "median": 701.0699999999999
      },
      "Peak_Speed_Mbps": {
        "type": "float64",
        "missing_values": 0,
        "unique_values": 58765,
        "min": 20.03,
        "max": 3999.78,
        "mean": 1512.427361728395,
        "median": 1397.65
      },
      "Congestion_Level": {
        "type": "float64",
        "missing_values": 0,
        "unique_values": 8587,
        "min": 0.0,
        "max": 100.0,
        "mean": 23.48457268518518,
        "median": 8.97
      }
    }
  },
  "column_names": [
    "Timestamp",
    "Region",
    "Service_Type",
    "Network_Type",
    "Traffic_Volume_GB",
    "Active_Users",
    "Bandwidth_Utilization_Percent",
    "Average_Speed_Mbps",
    "Peak_Speed_Mbps",
    "Congestion_Level"
  ],
  "results": {
    "总体数据统计分析单元": {
      "status": "success",
      "error": null,
      "code": "import pandas as pd\nimport os\nimport numpy as np\nfrom datetime import datetime\n\ndef analyze_csv_data(file_path, output_path):\n    \"\"\"\n    分析CSV文件并将结果保存为纯文本格式\n    \n    Args:\n        file_path (str): CSV文件路径\n        output_path (str): 输出文本文件路径\n    \"\"\"\n    try:\n        # 检查文件是否存在\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"文件 {file_path} 不存在\")\n\n        # 读取CSV文件\n        print(f\"正在读取文件: {file_path}\")\n        df = pd.read_csv(file_path)\n        \n        # 确保输出目录存在\n        output_dir = os.path.dirname(output_path)\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n            \n        # 打开输出文件\n        with open(output_path, 'w', encoding='utf-8') as f:\n            # 写入基本信息\n            f.write(\"=\" * 80 + \"\\n\")\n            f.write(f\"网络数据分析报告\\n\")\n            f.write(f\"生成时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n            f.write(f\"数据源文件: {file_path}\\n\")\n            f.write(\"=\" * 80 + \"\\n\\n\")\n            \n            # 1. 数据集基本信息\n            f.write(\"1. 数据集基本信息\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            f.write(f\"总行数: {len(df)}\\n\")\n            f.write(f\"总列数: {len(df.columns)}\\n\")\n            f.write(f\"数据集内存占用: {df.memory_usage(deep=True).sum() / (1024 * 1024):.2f} MB\\n\\n\")\n            \n            # 2. 数据类型概览\n            f.write(\"2. 数据类型概览\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            dtypes_info = {}\n            for dtype in df.dtypes.unique():\n                dtypes_info[str(dtype)] = sum(df.dtypes == dtype)\n            \n            for dtype, count in dtypes_info.items():\n                f.write(f\"{dtype}: {count} 列\\n\")\n            f.write(\"\\n\")\n            \n            # 3. 时间分析 (假设Timestamp是正确的时间戳格式)\n            f.write(\"3. 时间范围分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            try:\n                # 将Timestamp列转换为日期时间格式\n                if 'Timestamp' in df.columns:\n                    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n                    f.write(f\"时间范围: {df['Timestamp'].min()} 至 {df['Timestamp'].max()}\\n\")\n                    f.write(f\"数据跨度: {(df['Timestamp'].max() - df['Timestamp'].min()).days + 1} 天\\n\\n\")\n            except Exception as e:\n                f.write(f\"时间分析出错: {str(e)}\\n\\n\")\n            \n            # 4. 分类变量分析\n            categorical_columns = ['Region', 'Service_Type', 'Network_Type']\n            f.write(\"4. 分类变量分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            for col in categorical_columns:\n                if col in df.columns:\n                    f.write(f\"{col} 分布:\\n\")\n                    value_counts = df[col].value_counts()\n                    for value, count in value_counts.items():\n                        percentage = count / len(df) * 100\n                        f.write(f\"  - {value}: {count} 条记录 ({percentage:.2f}%)\\n\")\n                    f.write(\"\\n\")\n            \n            # 5. 数值变量分析\n            numeric_columns = ['Traffic_Volume_GB', 'Active_Users', 'Bandwidth_Utilization_Percent', \n                              'Average_Speed_Mbps', 'Peak_Speed_Mbps', 'Congestion_Level']\n            \n            f.write(\"5. 数值变量统计分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            for col in numeric_columns:\n                if col in df.columns:\n                    f.write(f\"{col} 统计:\\n\")\n                    f.write(f\"  - 最小值: {df[col].min():.2f}\\n\")\n                    f.write(f\"  - 最大值: {df[col].max():.2f}\\n\")\n                    f.write(f\"  - 平均值: {df[col].mean():.2f}\\n\")\n                    f.write(f\"  - 中位数: {df[col].median():.2f}\\n\")\n                    f.write(f\"  - 标准差: {df[col].std():.2f}\\n\")\n                    \n                    # 百分位数\n                    percentiles = [0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n                    perc_values = np.percentile(df[col].dropna(), [p*100 for p in percentiles])\n                    f.write(f\"  - 百分位数:\\n\")\n                    for p, val in zip(percentiles, perc_values):\n                        f.write(f\"      {int(p*100) if p*100 == int(p*100) else p*100}%: {val:.2f}\\n\")\n                    f.write(\"\\n\")\n            \n            # 6. 按区域和网络类型的统计\n            f.write(\"6. 按区域和网络类型的流量分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            if all(col in df.columns for col in ['Region', 'Network_Type', 'Traffic_Volume_GB']):\n                # 按区域和网络类型计算平均流量\n                region_network_stats = df.groupby(['Region', 'Network_Type'])['Traffic_Volume_GB'].agg(\n                    ['mean', 'sum', 'count']).reset_index()\n                \n                for _, row in region_network_stats.iterrows():\n                    region = row['Region']\n                    network = row['Network_Type']\n                    avg_traffic = row['mean']\n                    total_traffic = row['sum']\n                    record_count = row['count']\n                    \n                    f.write(f\"区域: {region}, 网络类型: {network}\\n\")\n                    f.write(f\"  - 平均流量: {avg_traffic:.2f} GB\\n\")\n                    f.write(f\"  - 总流量: {total_traffic:.2f} GB\\n\")\n                    f.write(f\"  - 记录数: {record_count}\\n\")\n                f.write(\"\\n\")\n            \n            # 7. 按服务类型的统计\n            f.write(\"7. 按服务类型的性能分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            if all(col in df.columns for col in ['Service_Type', 'Average_Speed_Mbps', 'Congestion_Level']):\n                service_stats = df.groupby('Service_Type').agg({\n                    'Average_Speed_Mbps': ['mean', 'min', 'max'],\n                    'Congestion_Level': ['mean', 'min', 'max'],\n                    'Traffic_Volume_GB': ['sum', 'mean']\n                }).reset_index()\n                \n                for _, row in service_stats.iterrows():\n                    service = row[('Service_Type', '')]\n                    avg_speed = row[('Average_Speed_Mbps', 'mean')]\n                    avg_congestion = row[('Congestion_Level', 'mean')]\n                    total_traffic = row[('Traffic_Volume_GB', 'sum')]\n                    \n                    f.write(f\"服务类型: {service}\\n\")\n                    f.write(f\"  - 平均速度: {avg_speed:.2f} Mbps\\n\")\n                    f.write(f\"  - 平均拥塞度: {avg_congestion:.2f}%\\n\")\n                    f.write(f\"  - 总流量: {total_traffic:.2f} GB\\n\")\n                f.write(\"\\n\")\n            \n            # 8. 高峰期分析\n            f.write(\"8. 网络高峰期分析\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            if 'Timestamp' in df.columns and 'Traffic_Volume_GB' in df.columns:\n                try:\n                    # 提取小时\n                    df['Hour'] = df['Timestamp'].dt.hour\n                    \n                    # 按小时统计平均流量\n                    hourly_traffic = df.groupby('Hour')['Traffic_Volume_GB'].mean().reset_index()\n                    peak_hour = hourly_traffic.loc[hourly_traffic['Traffic_Volume_GB'].idxmax()]['Hour']\n                    off_peak_hour = hourly_traffic.loc[hourly_traffic['Traffic_Volume_GB'].idxmin()]['Hour']\n                    \n                    f.write(f\"流量高峰时段: {peak_hour}:00\\n\")\n                    f.write(f\"流量低谷时段: {off_peak_hour}:00\\n\")\n                    \n                    # 列出各小时平均流量\n                    f.write(\"各小时平均流量:\\n\")\n                    for _, row in hourly_traffic.iterrows():\n                        hour = row['Hour']\n                        traffic = row['Traffic_Volume_GB']\n                        f.write(f\"  - {hour}:00: {traffic:.2f} GB\\n\")\n                    f.write(\"\\n\")\n                except Exception as e:\n                    f.write(f\"高峰期分析出错: {str(e)}\\n\\n\")\n            \n            # 9. 总结\n            f.write(\"9. 分析总结\\n\")\n            f.write(\"-\" * 50 + \"\\n\")\n            \n            # 计算一些关键指标\n            if all(col in df.columns for col in numeric_columns):\n                avg_traffic = df['Traffic_Volume_GB'].mean()\n                avg_users = df['Active_Users'].mean()\n                avg_bandwidth = df['Bandwidth_Utilization_Percent'].mean()\n                avg_speed = df['Average_Speed_Mbps'].mean()\n                avg_congestion = df['Congestion_Level'].mean()\n                \n                f.write(f\"数据集包含 {len(df)} 条网络性能记录，涵盖多个区域和服务类型。\\n\")\n                f.write(f\"平均流量为 {avg_traffic:.2f} GB，平均活跃用户数为 {avg_users:.2f}。\\n\")\n                f.write(f\"网络带宽利用率平均为 {avg_bandwidth:.2f}%，平均速度为 {avg_speed:.2f} Mbps。\\n\")\n                f.write(f\"网络拥塞度平均为 {avg_congestion:.2f}%。\\n\\n\")\n                \n                # 如果存在高拥塞情况，进行说明\n                high_congestion = df[df['Congestion_Level'] > 80]\n                if len(high_congestion) > 0:\n                    high_cong_percent = len(high_congestion) / len(df) * 100\n                    f.write(f\"高拥塞情况（拥塞度>80%）占总记录的 {high_cong_percent:.2f}%。\\n\")\n                \n            f.write(\"\\n分析完成。\")\n        \n        print(f\"分析完成，结果已保存至: {output_path}\")\n        return True\n    \n    except Exception as e:\n        print(f\"分析过程出错: {str(e)}\")\n        return False\n\nif __name__ == \"__main__\":\n    file_path = \"temp_csv/excel_data_20250317161158.csv\"\n    output_path = \"pngs/analysis_results.txt\"\n    analyze_csv_data(file_path, output_path)",
      "results": "正在读取文件: temp_csv/excel_data_20250317161158.csv\n分析完成，结果已保存至: pngs/analysis_results.txt\n",
      "txt_results": "================================================================================\n网络数据分析报告\n生成时间: 2025-03-17 16:12:48\n数据源文件: temp_csv/excel_data_20250317161158.csv\n================================================================================\n\n1. 数据集基本信息\n--------------------------------------------------\n总行数: 64800\n总列数: 10\n数据集内存占用: 17.21 MB\n\n2. 数据类型概览\n--------------------------------------------------\nobject: 4 列\nfloat64: 5 列\nint64: 1 列\n\n3. 时间范围分析\n--------------------------------------------------\n时间范围: 2025-02-01 00:00:00 至 2025-03-02 23:00:00\n数据跨度: 30 天\n\n4. 分类变量分析\n--------------------------------------------------\nRegion 分布:\n  - North: 12960 条记录 (20.00%)\n  - South: 12960 条记录 (20.00%)\n  - East: 12960 条记录 (20.00%)\n  - West: 12960 条记录 (20.00%)\n  - Central: 12960 条记录 (20.00%)\n\nService_Type 分布:\n  - Voice: 10800 条记录 (16.67%)\n  - Data: 10800 条记录 (16.67%)\n  - SMS: 10800 条记录 (16.67%)\n  - Video Streaming: 10800 条记录 (16.67%)\n  - Gaming: 10800 条记录 (16.67%)\n  - Social Media: 10800 条记录 (16.67%)\n\nNetwork_Type 分布:\n  - 4G: 21600 条记录 (33.33%)\n  - 5G: 21600 条记录 (33.33%)\n  - Fiber: 21600 条记录 (33.33%)\n\n5. 数值变量统计分析\n--------------------------------------------------\nTraffic_Volume_GB 统计:\n  - 最小值: 0.00\n  - 最大值: 19930.14\n  - 平均值: 1343.22\n  - 中位数: 456.97\n  - 标准差: 2045.60\n  - 百分位数:\n      10%: 19.68\n      25%: 96.59\n      50%: 456.97\n      75%: 1774.62\n      90%: 3796.48\n      95%: 5555.21\n      99%: 9622.65\n\nActive_Users 统计:\n  - 最小值: 0.00\n  - 最大值: 2445.00\n  - 平均值: 189.79\n  - 中位数: 96.00\n  - 标准差: 252.73\n  - 百分位数:\n      10%: 5.00\n      25%: 27.00\n      50%: 96.00\n      75%: 252.00\n      90%: 497.00\n      95%: 694.00\n      99%: 1197.04\n\nBandwidth_Utilization_Percent 统计:\n  - 最小值: 0.00\n  - 最大值: 95.00\n  - 平均值: 13.16\n  - 中位数: 4.55\n  - 标准差: 19.23\n  - 百分位数:\n      10%: 0.19\n      25%: 0.95\n      50%: 4.55\n      75%: 17.63\n      90%: 38.14\n      95%: 55.57\n      99%: 95.00\n\nAverage_Speed_Mbps 统计:\n  - 最小值: 10.02\n  - 最大值: 1999.88\n  - 平均值: 757.51\n  - 中位数: 701.07\n  - 标准差: 486.49\n  - 百分位数:\n      10%: 153.84\n      25%: 361.67\n      50%: 701.07\n      75%: 1074.03\n      90%: 1455.11\n      95%: 1694.06\n      99%: 1937.38\n\nPeak_Speed_Mbps 统计:\n  - 最小值: 20.03\n  - 最大值: 3999.78\n  - 平均值: 1512.43\n  - 中位数: 1397.65\n  - 标准差: 976.05\n  - 百分位数:\n      10%: 301.05\n      25%: 716.04\n      50%: 1397.65\n      75%: 2147.31\n      90%: 2909.17\n      95%: 3395.30\n      99%: 3877.58\n\nCongestion_Level 统计:\n  - 最小值: 0.00\n  - 最大值: 100.00\n  - 平均值: 23.48\n  - 中位数: 8.97\n  - 标准差: 29.88\n  - 百分位数:\n      10%: 0.38\n      25%: 1.90\n      50%: 8.97\n      75%: 34.86\n      90%: 75.52\n      95%: 100.00\n      99%: 100.00\n\n6. 按区域和网络类型的流量分析\n--------------------------------------------------\n区域: Central, 网络类型: 4G\n  - 平均流量: 904.10 GB\n  - 总流量: 3905701.67 GB\n  - 记录数: 4320\n区域: Central, 网络类型: 5G\n  - 平均流量: 1345.66 GB\n  - 总流量: 5813231.95 GB\n  - 记录数: 4320\n区域: Central, 网络类型: Fiber\n  - 平均流量: 1798.18 GB\n  - 总流量: 7768157.26 GB\n  - 记录数: 4320\n区域: East, 网络类型: 4G\n  - 平均流量: 897.48 GB\n  - 总流量: 3877109.46 GB\n  - 记录数: 4320\n区域: East, 网络类型: 5G\n  - 平均流量: 1340.47 GB\n  - 总流量: 5790834.15 GB\n  - 记录数: 4320\n区域: East, 网络类型: Fiber\n  - 平均流量: 1776.32 GB\n  - 总流量: 7673681.00 GB\n  - 记录数: 4320\n区域: North, 网络类型: 4G\n  - 平均流量: 904.22 GB\n  - 总流量: 3906219.48 GB\n  - 记录数: 4320\n区域: North, 网络类型: 5G\n  - 平均流量: 1348.18 GB\n  - 总流量: 5824131.57 GB\n  - 记录数: 4320\n区域: North, 网络类型: Fiber\n  - 平均流量: 1763.50 GB\n  - 总流量: 7618325.02 GB\n  - 记录数: 4320\n区域: South, 网络类型: 4G\n  - 平均流量: 899.39 GB\n  - 总流量: 3885374.56 GB\n  - 记录数: 4320\n区域: South, 网络类型: 5G\n  - 平均流量: 1333.37 GB\n  - 总流量: 5760178.82 GB\n  - 记录数: 4320\n区域: South, 网络类型: Fiber\n  - 平均流量: 1791.30 GB\n  - 总流量: 7738402.57 GB\n  - 记录数: 4320\n区域: West, 网络类型: 4G\n  - 平均流量: 897.62 GB\n  - 总流量: 3877718.03 GB\n  - 记录数: 4320\n区域: West, 网络类型: 5G\n  - 平均流量: 1325.26 GB\n  - 总流量: 5725127.05 GB\n  - 记录数: 4320\n区域: West, 网络类型: Fiber\n  - 平均流量: 1823.32 GB\n  - 总流量: 7876744.88 GB\n  - 记录数: 4320\n\n7. 按服务类型的性能分析\n--------------------------------------------------\n服务类型: Data\n  - 平均速度: 751.64 Mbps\n  - 平均拥塞度: 38.09%\n  - 总流量: 22594260.16 GB\n服务类型: Gaming\n  - 平均速度: 757.76 Mbps\n  - 平均拥塞度: 17.36%\n  - 总流量: 9385600.12 GB\n服务类型: SMS\n  - 平均速度: 750.54 Mbps\n  - 平均拥塞度: 1.76%\n  - 总流量: 951959.99 GB\n服务类型: Social Media\n  - 平均速度: 765.14 Mbps\n  - 平均拥塞度: 26.13%\n  - 总流量: 14348340.77 GB\n服务类型: Video Streaming\n  - 平均速度: 759.31 Mbps\n  - 平均拥塞度: 53.38%\n  - 总流量: 37491047.40 GB\n服务类型: Voice\n  - 平均速度: 760.69 Mbps\n  - 平均拥塞度: 4.19%\n  - 总流量: 2269729.03 GB\n\n8. 网络高峰期分析\n--------------------------------------------------\n流量高峰时段: 7.0:00\n流量低谷时段: 18.0:00\n各小时平均流量:\n  - 0.0:00: 1332.72 GB\n  - 1.0:00: 1686.29 GB\n  - 2.0:00: 2048.61 GB\n  - 3.0:00: 2298.67 GB\n  - 4.0:00: 2460.65 GB\n  - 5.0:00: 2622.43 GB\n  - 6.0:00: 2661.28 GB\n  - 7.0:00: 2664.41 GB\n  - 8.0:00: 2525.76 GB\n  - 9.0:00: 2246.13 GB\n  - 10.0:00: 2041.61 GB\n  - 11.0:00: 1706.24 GB\n  - 12.0:00: 1356.45 GB\n  - 13.0:00: 1002.47 GB\n  - 14.0:00: 672.54 GB\n  - 15.0:00: 393.29 GB\n  - 16.0:00: 176.84 GB\n  - 17.0:00: 46.37 GB\n  - 18.0:00: 0.00 GB\n  - 19.0:00: 45.56 GB\n  - 20.0:00: 181.78 GB\n  - 21.0:00: 394.99 GB\n  - 22.0:00: 668.78 GB\n  - 23.0:00: 1003.52 GB\n\n9. 分析总结\n--------------------------------------------------\n数据集包含 64800 条网络性能记录，涵盖多个区域和服务类型。\n平均流量为 1343.22 GB，平均活跃用户数为 189.79。\n网络带宽利用率平均为 13.16%，平均速度为 757.51 Mbps。\n网络拥塞度平均为 23.48%。\n\n高拥塞情况（拥塞度>80%）占总记录的 9.17%。\n\n分析完成。",
      "report_file": "reports\\总体数据统计分析_20250317_161438.md"
    },
    "分组对比分析单元": {
      "status": "success",
      "error": null,
      "code": "import pandas as pd\nimport numpy as np\nimport os\nfrom datetime import datetime\n\ndef read_csv_file(file_path):\n    \"\"\"读取CSV文件并返回DataFrame\"\"\"\n    try:\n        df = pd.read_csv(file_path)\n        print(f\"成功读取CSV文件，共{len(df)}行数据\")\n        return df\n    except FileNotFoundError:\n        print(f\"错误: 文件 '{file_path}' 不存在\")\n        return None\n    except Exception as e:\n        print(f\"读取CSV文件时出错: {str(e)}\")\n        return None\n\ndef analyze_column_distribution(df):\n    \"\"\"分析数值列和分类列的分布\"\"\"\n    result = []\n    result.append(\"=== 数据列分布分析 ===\\n\")\n    \n    # 分析分类列\n    categorical_cols = ['Region', 'Service_Type', 'Network_Type']\n    result.append(\"--- 分类列分布 ---\")\n    \n    for col in categorical_cols:\n        result.append(f\"\\n{col}分布:\")\n        value_counts = df[col].value_counts()\n        for value, count in value_counts.items():\n            percentage = count / len(df) * 100\n            result.append(f\"  {value}: {count}条记录 ({percentage:.2f}%)\")\n    \n    # 分析数值列\n    numeric_cols = ['Traffic_Volume_GB', 'Active_Users', 'Bandwidth_Utilization_Percent', \n                    'Average_Speed_Mbps', 'Peak_Speed_Mbps', 'Congestion_Level']\n    \n    result.append(\"\\n\\n--- 数值列统计 ---\")\n    for col in numeric_cols:\n        result.append(f\"\\n{col}统计:\")\n        result.append(f\"  最小值: {df[col].min():.2f}\")\n        result.append(f\"  最大值: {df[col].max():.2f}\")\n        result.append(f\"  平均值: {df[col].mean():.2f}\")\n        result.append(f\"  中位数: {df[col].median():.2f}\")\n        result.append(f\"  标准差: {df[col].std():.2f}\")\n        \n        # 分位数\n        q25, q75 = df[col].quantile([0.25, 0.75])\n        result.append(f\"  25%分位数: {q25:.2f}\")\n        result.append(f\"  75%分位数: {q75:.2f}\")\n    \n    return \"\\n\".join(result)\n\ndef group_comparison_analysis(df):\n    \"\"\"对数据进行分组统计，比较不同组之间的差异\"\"\"\n    result = []\n    result.append(\"\\n\\n=== 分组对比分析 ===\\n\")\n    \n    # 数值型指标\n    metrics = ['Traffic_Volume_GB', 'Active_Users', 'Bandwidth_Utilization_Percent', \n              'Average_Speed_Mbps', 'Peak_Speed_Mbps', 'Congestion_Level']\n    \n    # 按Region分组分析\n    result.append(\"--- 按Region分组分析 ---\\n\")\n    region_group = df.groupby('Region')[metrics].agg(['mean', 'median', 'max'])\n    result.append(format_group_results(region_group))\n    \n    # 按Network_Type分组分析\n    result.append(\"\\n--- 按Network_Type分组分析 ---\\n\")\n    network_group = df.groupby('Network_Type')[metrics].agg(['mean', 'median', 'max'])\n    result.append(format_group_results(network_group))\n    \n    # 按Service_Type分组分析\n    result.append(\"\\n--- 按Service_Type分组分析 ---\\n\")\n    service_group = df.groupby('Service_Type')[metrics].agg(['mean', 'median', 'max'])\n    result.append(format_group_results(service_group))\n    \n    # 交叉分组: Region x Network_Type\n    result.append(\"\\n--- 交叉分组: Region x Network_Type ---\\n\")\n    cross_group = df.groupby(['Region', 'Network_Type'])['Traffic_Volume_GB', 'Congestion_Level'].mean()\n    result.append(format_cross_group_results(cross_group))\n    \n    # 按时间段分组分析\n    result.append(\"\\n--- 按时间段分组分析 ---\\n\")\n    # 确保Timestamp列是datetime类型\n    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n    df['Hour'] = df['Timestamp'].dt.hour\n    \n    # 定义时间段\n    time_periods = {\n        '凌晨 (00:00-05:59)': (0, 5),\n        '上午 (06:00-11:59)': (6, 11),\n        '下午 (12:00-17:59)': (12, 17),\n        '晚上 (18:00-23:59)': (18, 23)\n    }\n    \n    time_stats = []\n    for period, (start, end) in time_periods.items():\n        period_df = df[(df['Hour'] >= start) & (df['Hour'] <= end)]\n        traffic_mean = period_df['Traffic_Volume_GB'].mean()\n        users_mean = period_df['Active_Users'].mean()\n        congestion_mean = period_df['Congestion_Level'].mean()\n        \n        time_stats.append(f\"{period}:\\n\"\n                          f\"  平均流量: {traffic_mean:.2f} GB\\n\"\n                          f\"  平均活跃用户: {users_mean:.2f}\\n\"\n                          f\"  平均拥塞度: {congestion_mean:.2f}%\")\n    \n    result.append(\"\\n\".join(time_stats))\n    \n    # 高负载分析\n    result.append(\"\\n\\n--- 高负载分析 ---\\n\")\n    high_load = df[df['Congestion_Level'] > 70]\n    result.append(f\"高负载记录数 (拥塞度 > 70%): {len(high_load)}条 ({len(high_load)/len(df)*100:.2f}%)\")\n    \n    if len(high_load) > 0:\n        # 高负载区域分布\n        region_load = high_load['Region'].value_counts()\n        result.append(\"\\n高负载区域分布:\")\n        for region, count in region_load.items():\n            result.append(f\"  {region}: {count}条 ({count/len(high_load)*100:.2f}%)\")\n        \n        # 高负载网络类型分布\n        network_load = high_load['Network_Type'].value_counts()\n        result.append(\"\\n高负载网络类型分布:\")\n        for network, count in network_load.items():\n            result.append(f\"  {network}: {count}条 ({count/len(high_load)*100:.2f}%)\")\n        \n        # 高负载服务类型分布\n        service_load = high_load['Service_Type'].value_counts()\n        result.append(\"\\n高负载服务类型分布:\")\n        for service, count in service_load.items():\n            result.append(f\"  {service}: {count}条 ({count/len(high_load)*100:.2f}%)\")\n    \n    return \"\\n\".join(result)\n\ndef format_group_results(group_df):\n    \"\"\"格式化分组结果为可读文本\"\"\"\n    result = []\n    \n    # 获取组索引\n    groups = group_df.index.tolist()\n    \n    # 遍历每个指标\n    for metric in group_df.columns.levels[0]:\n        result.append(f\"{metric}:\")\n        \n        # 遍历每个统计量\n        for stat in ['mean', 'median', 'max']:\n            result.append(f\"  {stat.capitalize()}:\")\n            \n            # 遍历每个组\n            for group in groups:\n                value = group_df.loc[group, (metric, stat)]\n                result.append(f\"    {group}: {value:.2f}\")\n    \n    return \"\\n\".join(result)\n\ndef format_cross_group_results(cross_group):\n    \"\"\"格式化交叉分组结果为可读文本\"\"\"\n    result = []\n    \n    # 重塑DataFrame以便更容易格式化\n    formatted_df = cross_group.reset_index()\n    \n    for metric in ['Traffic_Volume_GB', 'Congestion_Level']:\n        result.append(f\"{metric}:\")\n        \n        # 获取唯一的Region和Network_Type值\n        regions = formatted_df['Region'].unique()\n        network_types = formatted_df['Network_Type'].unique()\n        \n        for region in regions:\n            region_data = []\n            region_data.append(f\"  {region}:\")\n            \n            for network_type in network_types:\n                value = formatted_df[(formatted_df['Region'] == region) & \n                                    (formatted_df['Network_Type'] == network_type)][metric]\n                \n                if not value.empty:\n                    region_data.append(f\"    {network_type}: {value.values[0]:.2f}\")\n            \n            result.append(\"\\n\".join(region_data))\n    \n    return \"\\n\".join(result)\n\ndef main(file_path, output_path):\n    \"\"\"主函数，执行数据分析和结果输出\"\"\"\n    # 确保输出目录存在\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    \n    # 读取CSV文件\n    df = read_csv_file(file_path)\n    if df is None:\n        return\n    \n    try:\n        # 分析列分布\n        distribution_analysis = analyze_column_distribution(df)\n        \n        # 执行分组对比分析\n        group_analysis = group_comparison_analysis(df)\n        \n        # 组合所有分析结果\n        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        header = f\"网络数据分组对比分析报告\\n生成时间: {current_time}\\n文件: {file_path}\\n记录数: {len(df)}\\n\\n\"\n        \n        # 保存结果到文本文件\n        with open(output_path, 'w', encoding='utf-8') as f:\n            f.write(header)\n            f.write(distribution_analysis)\n            f.write(group_analysis)\n        \n        print(f\"分析结果已保存到 {output_path}\")\n    \n    except Exception as e:\n        print(f\"分析过程中出错: {str(e)}\")\n\nif __name__ == \"__main__\":\n    file_path = \"temp_csv/excel_data_20250317161158.csv\"\n    output_path = \"pngs/group_comparison_results.txt\"\n    main(file_path, output_path)",
      "results": "成功读取CSV文件，共64800行数据\n分析过程中出错: Cannot subset columns with a tuple with more than one element. Use a list instead.\n",
      "txt_results": "Customer Complaint Analysis Report\n==================================\n\nData Distribution Analysis:\n==============================\n\nComplaint_ID:\n  Top 3 categories:\n    COMP-01984: 1 (0.05%)\n    COMP-01983: 1 (0.05%)\n    COMP-01982: 1 (0.05%)\n\nDate_Reported:\n  Top 3 categories:\n    2025-03-28: 37 (1.85%)\n    2025-01-01: 33 (1.65%)\n    2025-03-07: 31 (1.55%)\n\nCustomer_ID:\n  Top 3 categories:\n    CUST-8483: 3 (0.15%)\n    CUST-4227: 3 (0.15%)\n    CUST-1815: 3 (0.15%)\n\nRegion:\n  Top 3 categories:\n    North: 417 (20.85%)\n    Central: 405 (20.25%)\n    South: 403 (20.15%)\n\nComplaint_Type:\n  Top 3 categories:\n    Call Drop: 296 (14.80%)\n    SMS Failure: 289 (14.45%)\n    Service Outage: 289 (14.45%)\n\nService_Type:\n  Top 3 categories:\n    Mobile: 508 (25.40%)\n    Broadband: 508 (25.40%)\n    Fixed Line: 494 (24.70%)\n\nDescription:\n  Top 3 categories:\n    Customer reported call drop issue: 320 (16.00%)\n    Customer reported slow internet issue: 294 (14.70%)\n    Customer reported service outage issue: 286 (14.30%)\n\nPriority:\n  Top 3 categories:\n    Critical: 526 (26.30%)\n    Medium: 500 (25.00%)\n    Low: 495 (24.75%)\n\nStatus:\n  Top 3 categories:\n    Closed: 1702 (85.10%)\n    In Progress: 111 (5.55%)\n    Resolved: 99 (4.95%)\n\nResolution_Date:\n  Top 3 categories:\n    2025-03-12: 28 (1.40%)\n    2025-03-26: 25 (1.25%)\n    2025-03-23: 24 (1.20%)\n\nResolution_Time_Days:\n  Mean: 7.15\n  Median: 7.00\n  Std Dev: 4.40\n\nCustomer_Satisfaction:\n  Mean: 3.02\n  Median: 3.00\n  Std Dev: 1.41\n\n\nGroup Comparison Analysis:\n==============================\n\nGrouping by Region:\n  Resolution_Time_Days:\n    Central: Mean=7.2, Median=7.0, Std Dev=4.48\n    East: Mean=7.18, Median=7.0, Std Dev=4.51\n    North: Mean=7.22, Median=7.0, Std Dev=4.33\n    South: Mean=7.05, Median=7.0, Std Dev=4.31\n    West: Mean=7.11, Median=7.0, Std Dev=4.41\n  Customer_Satisfaction:\n    Central: Mean=2.93, Median=3.0, Std Dev=1.37\n    East: Mean=2.99, Median=3.0, Std Dev=1.39\n    North: Mean=3.0, Median=3.0, Std Dev=1.48\n    South: Mean=3.15, Median=3.0, Std Dev=1.39\n    West: Mean=3.0, Median=3.0, Std Dev=1.4\n\nGrouping by Service_Type:\n  Resolution_Time_Days:\n    Broadband: Mean=7.18, Median=7.0, Std Dev=4.5\n    Fixed Line: Mean=7.19, Median=7.0, Std Dev=4.46\n    Mobile: Mean=7.14, Median=7.0, Std Dev=4.31\n    TV: Mean=7.11, Median=7.0, Std Dev=4.36\n  Customer_Satisfaction:\n    Broadband: Mean=3.12, Median=3.0, Std Dev=1.4\n    Fixed Line: Mean=2.99, Median=3.0, Std Dev=1.43\n    Mobile: Mean=2.98, Median=3.0, Std Dev=1.4\n    TV: Mean=2.98, Median=3.0, Std Dev=1.41\n\nGrouping by Priority:\n  Resolution_Time_Days:\n    Critical: Mean=7.44, Median=7.0, Std Dev=4.39\n    High: Mean=7.38, Median=8.0, Std Dev=4.45\n    Low: Mean=6.89, Median=7.0, Std Dev=4.39\n    Medium: Mean=6.9, Median=7.0, Std Dev=4.38\n  Customer_Satisfaction:\n    Critical: Mean=3.06, Median=3.0, Std Dev=1.41\n    High: Mean=3.03, Median=3.0, Std Dev=1.46\n    Low: Mean=2.93, Median=3.0, Std Dev=1.38\n    Medium: Mean=3.04, Median=3.0, Std Dev=1.39\n\n",
      "report_file": "reports\\分组对比分析_20250317_161721.md"
    },
    "比例分析单元": {
      "status": "success",
      "error": null,
      "code": "import pandas as pd\nimport os\nfrom datetime import datetime\n\ndef analyze_csv_distributions(file_path, output_path):\n    \"\"\"\n    分析CSV文件中分类列的分布情况，计算各类别的占比，并将结果保存为纯文本\n    \n    参数:\n    file_path (str): CSV文件路径\n    output_path (str): 输出结果的文本文件路径\n    \"\"\"\n    try:\n        # 检查文件是否存在\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"文件未找到: {file_path}\")\n        \n        # 读取CSV文件\n        print(f\"正在读取文件: {file_path}\")\n        df = pd.read_csv(file_path)\n        \n        # 确认数据加载成功\n        print(f\"成功加载数据，共 {len(df)} 行，{len(df.columns)} 列\")\n        \n        # 创建输出目录（如果不存在）\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        \n        # 准备写入分析结果\n        with open(output_path, 'w', encoding='utf-8') as f:\n            # 写入标题和时间戳\n            f.write(\"=\" * 80 + \"\\n\")\n            f.write(f\"CSV文件分类数据分布分析\\n\")\n            f.write(f\"文件路径: {file_path}\\n\")\n            f.write(f\"分析时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n            f.write(\"=\" * 80 + \"\\n\\n\")\n            \n            # 识别分类列（对象类型的列，除了Timestamp）\n            categorical_columns = [col for col in df.columns if df[col].dtype == 'object' and col != 'Timestamp']\n            f.write(f\"分类列识别结果: {', '.join(categorical_columns)}\\n\\n\")\n            \n            # 分析每个分类列的分布\n            for column in categorical_columns:\n                f.write(\"-\" * 80 + \"\\n\")\n                f.write(f\"{column} 分布情况\\n\")\n                f.write(\"-\" * 80 + \"\\n\\n\")\n                \n                # 计算分布数量和占比\n                value_counts = df[column].value_counts()\n                total_count = len(df)\n                \n                # 创建表格标题\n                f.write(f\"{'类别':<20} {'数量':<10} {'占比':<10}\\n\")\n                f.write(f\"{'-'*20} {'-'*10} {'-'*10}\\n\")\n                \n                # 写入各个类别的数量和占比\n                for category, count in value_counts.items():\n                    percentage = (count / total_count) * 100\n                    f.write(f\"{str(category):<20} {count:<10} {percentage:.2f}%\\n\")\n                \n                # 计算汇总信息\n                f.write(f\"{'-'*20} {'-'*10} {'-'*10}\\n\")\n                f.write(f\"{'总计':<20} {total_count:<10} 100.00%\\n\\n\")\n                \n                # 添加额外的分析信息\n                f.write(f\"类别数量: {len(value_counts)}\\n\")\n                f.write(f\"最常见类别: {value_counts.index[0]} ({value_counts.iloc[0]} 次，占比 {(value_counts.iloc[0]/total_count)*100:.2f}%)\\n\")\n                f.write(f\"最少见类别: {value_counts.index[-1]} ({value_counts.iloc[-1]} 次，占比 {(value_counts.iloc[-1]/total_count)*100:.2f}%)\\n\\n\")\n            \n            # 添加最后的总结\n            f.write(\"=\" * 80 + \"\\n\")\n            f.write(\"分析总结\\n\")\n            f.write(\"=\" * 80 + \"\\n\\n\")\n            \n            # 计算每个分类列的熵作为多样性指标\n            for column in categorical_columns:\n                probs = df[column].value_counts(normalize=True)\n                entropy = -sum(probs * probs.apply(lambda x: pd.np.log2(x) if x > 0 else 0))\n                normalized_entropy = entropy / pd.np.log2(len(probs)) if len(probs) > 1 else 0\n                \n                f.write(f\"{column} 多样性指标: {normalized_entropy:.4f} (0表示单一值，1表示完全均匀分布)\\n\")\n            \n            f.write(\"\\n分析完成！\\n\")\n        \n        print(f\"分析结果已保存到: {output_path}\")\n        return True\n        \n    except Exception as e:\n        print(f\"处理数据时出错: {str(e)}\")\n        return False\n\nif __name__ == \"__main__\":\n    # 文件路径\n    csv_file_path = \"temp_csv/excel_data_20250317161158.csv\"\n    output_file_path = \"pngs/category_distribution_results.txt\"\n    \n    # 执行分析\n    success = analyze_csv_distributions(csv_file_path, output_file_path)\n    \n    if success:\n        print(\"分析成功完成！\")\n    else:\n        print(\"分析过程中出现错误。\")",
      "results": "正在读取文件: temp_csv/excel_data_20250317161158.csv\n成功加载数据，共 64800 行，10 列\n处理数据时出错: module 'pandas' has no attribute 'np'\n分析过程中出现错误。\n",
      "txt_results": "================================================================================\nCSV文件分类数据分布分析\n文件路径: temp_csv/excel_data_20250317161158.csv\n分析时间: 2025-03-17 16:17:49\n================================================================================\n\n分类列识别结果: Region, Service_Type, Network_Type\n\n--------------------------------------------------------------------------------\nRegion 分布情况\n--------------------------------------------------------------------------------\n\n类别                   数量         占比        \n-------------------- ---------- ----------\nNorth                12960      20.00%\nSouth                12960      20.00%\nEast                 12960      20.00%\nWest                 12960      20.00%\nCentral              12960      20.00%\n-------------------- ---------- ----------\n总计                   64800      100.00%\n\n类别数量: 5\n最常见类别: North (12960 次，占比 20.00%)\n最少见类别: Central (12960 次，占比 20.00%)\n\n--------------------------------------------------------------------------------\nService_Type 分布情况\n--------------------------------------------------------------------------------\n\n类别                   数量         占比        \n-------------------- ---------- ----------\nVoice                10800      16.67%\nData                 10800      16.67%\nSMS                  10800      16.67%\nVideo Streaming      10800      16.67%\nGaming               10800      16.67%\nSocial Media         10800      16.67%\n-------------------- ---------- ----------\n总计                   64800      100.00%\n\n类别数量: 6\n最常见类别: Voice (10800 次，占比 16.67%)\n最少见类别: Social Media (10800 次，占比 16.67%)\n\n--------------------------------------------------------------------------------\nNetwork_Type 分布情况\n--------------------------------------------------------------------------------\n\n类别                   数量         占比        \n-------------------- ---------- ----------\n4G                   21600      33.33%\n5G                   21600      33.33%\nFiber                21600      33.33%\n-------------------- ---------- ----------\n总计                   64800      100.00%\n\n类别数量: 3\n最常见类别: 4G (21600 次，占比 33.33%)\n最少见类别: Fiber (21600 次，占比 33.33%)\n\n================================================================================\n分析总结\n================================================================================\n\n",
      "report_file": "reports\\比例分析_20250317_161821.md"
    },
    "时间趋势分析单元": {
      "status": "failed",
      "error": "生成代码失败",
      "code": null,
      "results": null
    }
  }
}